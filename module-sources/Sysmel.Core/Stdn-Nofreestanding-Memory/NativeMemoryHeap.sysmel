namespace Stdn definition: {
namespace Memory definition: {

#**
 * NativeMemoryHeap
 * A data structure for implementing malloc/free and family.
 * This implementation is partially based on jemalloc:
 *        this is jemalloc (A Scalable Concurrent malloc(3) Implementation for FreeBSD
 *        -- https:##www.bsdcan.org/2006/papers/jemalloc.pdf )
 * TODO: - Per processor arenas.
 *       - Dedicated chunk allocation.
 *#
class NativeMemoryHeap definition: {
    compileTime constant MemoryChunkSize := 16r200000 castTo: UIntPointer.
    compileTime constant MemoryChunkAlignment := 16r200000 castTo: UIntPointer.
    compileTime constant HugeAllocationThreshold := MemoryChunkSize / 2 castTo: UIntPointer.
    compileTime constant LargeAllocationThreshold := 16r1000 castTo: UIntPointer.

    compileTime constant MemoryChunkBlockSize := 16r800.
    compileTime constant MemoryChunkBlockCount := MemoryChunkSize / MemoryChunkBlockSize.

    compileTime constant ChunkBuddyMemoryAllocator := FixedSizeBuddyBlockAllocator(MemoryChunkBlockCount).

    compileTime constant AllocationType_Small := 0.
    compileTime constant AllocationType_Large := 1.
    compileTime constant AllocationType_Huge := 2.

    compileTime constant QuantumSpacedCategories := 512 / 16.
    compileTime constant SweepPredicateBlock := ((Void pointer) => Boolean8) nativeStackBlockClosure.

    #**
     * A common chunk header
     *#
    struct CommonChunkHeader definition: {
        field isHugeAllocation public type: Boolean8.
    }.

    struct HugeChunkHeader definition: {
        field commonHeader public type: CommonChunkHeader.
        field allocationSize public type: UIntPointer.
    }.

    compileTime constant HugeChunkHeaderSize := HugeChunkHeader instanceSize alignedTo: 16.

    #**
     * A memory allocation chunk header.
     *#
    struct NormalChunkHeader definition: {
        field commonHeader public type: CommonChunkHeader.

        field previousChunk public type: NormalChunkHeader pointer.
        field nextChunk public type: NormalChunkHeader pointer.

        field initialFreeBlockCount public type: ChunkBuddyMemoryAllocator BlockIndexType.

        field buddyMemoryAllocator public type: ChunkBuddyMemoryAllocator.

        method isCompletelyFree => Boolean8
            := initialFreeBlockCount == buddyMemoryAllocator currentFreeLeafBlockCount.
    }.

    #**
     * Quantum spaced category run
     *#
    struct SlabHeader definition: {
        compileTime constant MaxNumberOfElements := 256.
        compileTime constant WordBitCount := UIntPointer instanceSize*8.
        compileTime constant BitmapWords := MaxNumberOfElements / WordBitCount.
        compileTime constant FullWord := -1 castTo: UIntPointer.

        ## Linked list between all slabs.
        field previousSlab public type: SlabHeader pointer.
        field nextSlab public type: SlabHeader pointer.

        ## Linked list between active slabs.
        field previousActiveSlab public type: SlabHeader pointer.
        field nextActiveSlab public type: SlabHeader pointer.

        field elementSize public type: UInt16.
        field elementCount public type: UInt16.
        field freeCount public type: UInt16.
        field category public type: UInt8.
        field _ type: UInt8.

        field bitmap public type: (UIntPointer array: BitmapWords).

        method setupForElements: (count: UIntPointer) ::=> Void := {
            elementCount := count castTo: UInt16.
            freeCount := count castTo: UInt16.

            let bitmapWordCount := self bitmapWordCount.
            let lastWordFreeElements := elementCount % WordBitCount castTo: UInt16.
            lastWordFreeElements ~~ 0 ifTrue: {
                ## Mark the unused elements in the bitmap as allocated.
                let lastWordFreeElementsMask := ((1 castTo: UIntPointer) << lastWordFreeElements) - 1 castTo: UIntPointer.
                let lastWordUnusedElementsMask := lastWordFreeElementsMask bitInvert.
                bitmap[bitmapWordCount - 1] := lastWordUnusedElementsMask.
            }.
        }.

        method bitmapWordCount => UIntPointer
            := (elementCount + WordBitCount - 1 castTo: UIntPointer) / WordBitCount.

        method findFreeElementIndex => Int32 := {
            let bitmapWordCount := self bitmapWordCount.

            for: (let i mutable type: UIntPointer := 0) while: (i < bitmapWordCount) do: {
                bitmap[i] ~~ FullWord ifTrue: {
                    let freeBit := bitmap[i] bitInvert lowBit.
                    freeBit ~= 0 ifTrue: {
                        return: (i*WordBitCount + freeBit - 1 castTo: Int32)
                    }.
                }
            } continueWith: (i := i + 1).

            -1
        }.

        method isMarkedElement: (elementIndex: UIntPointer) ::=> Boolean8 := {
            let wordIndex := elementIndex / WordBitCount.
            let wordBitIndex := elementIndex % WordBitCount.
            let bit := (1 castTo: UIntPointer) << wordBitIndex.
            bitmap[wordIndex] anyMask: bit.
        }.

        method markElement: (elementIndex: UIntPointer) ::=> Void := {
            let wordIndex := elementIndex / WordBitCount.
            let wordBitIndex := elementIndex % WordBitCount.
            let bit := (1 castTo: UIntPointer) << wordBitIndex.
            bitmap[wordIndex] := bitmap[wordIndex] | bit.

            freeCount := freeCount - 1 castTo: UInt16
        }.

        method unmarkElement: (elementIndex: UIntPointer) ::=> Void := {
            let wordIndex := elementIndex / WordBitCount.
            let wordBitIndex := elementIndex % WordBitCount.
            let bit := (1 castTo: UIntPointer) << wordBitIndex.
            bitmap[wordIndex] := bitmap[wordIndex] & bit bitInvert.

            freeCount := freeCount + 1 castTo: UInt16
        }.

        method isCompletelyFree => Boolean8
            := freeCount == elementCount.
    }.

    compileTime constant SlabHeaderSize := SlabHeader instanceSize alignedTo: 16.

    #**
     * Quantum space category active run state.
     *#
    struct QuantumSpacedCategoryState definition: {
        field firstActiveSlab public type: SlabHeader pointer.
        field lastActiveSlab public type: SlabHeader pointer.

        field firstSlab public type: SlabHeader pointer.
        field lastSlab public type: SlabHeader pointer.

        method isActiveSlab: (slab: SlabHeader pointer) ::=> Boolean8
            := firstActiveSlab == slab || lastActiveSlab == slab ||
            slab _ previousActiveSlab isNotNil || slab _ nextActiveSlab isNotNil.

        method addSlab: (slab: SlabHeader pointer) ::=> Void := {
            firstSlab ifNil: {
                assert: lastSlab isNil.
                firstSlab := lastSlab := slab
            } ifNotNil: {
                slab _ nextSlab: firstSlab.
                firstSlab _ previousSlab: slab.
                firstSlab := slab
            }.
        }.

        method removeSlab: (slab: SlabHeader pointer) ::=> Void := {
            slab _ previousSlab ifNil: {
                firstSlab := slab _ nextSlab.
            } ifNotNil: {
                slab _ previousSlab _ nextSlab: slab _ nextSlab.
            }.

            slab _ nextSlab ifNil: {
                lastSlab := slab _ previousSlab.
            } ifNotNil: {
                slab _ nextSlab _ previousSlab: slab _ previousSlab.
            }.

            slab _
                previousSlab: nil;
                nextSlab: nil.
        }.

        method activateSlab: (slab: SlabHeader pointer) ::=> Void := {
            assert: slab _ previousActiveSlab isNil.
            assert: slab _ nextActiveSlab isNil.
            firstActiveSlab ifNil: {
                assert: lastActiveSlab isNil.
                firstActiveSlab := lastActiveSlab := slab
            } ifNotNil: {
                slab _ nextActiveSlab: firstActiveSlab.
                firstActiveSlab _ previousActiveSlab: slab.
                firstActiveSlab := slab
            }
        }.

        method deactivateSlab: (slab: SlabHeader pointer) ::=> Void := {
            slab _ previousActiveSlab ifNil: {
                firstActiveSlab := slab _ nextActiveSlab.
            } ifNotNil: {
                slab _ previousActiveSlab _ nextActiveSlab: slab _ nextActiveSlab.
            }.

            slab _ nextActiveSlab ifNil: {
                lastActiveSlab := slab _ previousActiveSlab.
            } ifNotNil: {
                slab _ nextActiveSlab _ previousActiveSlab: slab _ previousActiveSlab.
            }.

            slab _
                previousActiveSlab: nil;
                nextActiveSlab: nil.
        }.

    }.

    field mutex private type: MemoryHeapMutex.
    field firstChunk private type: NormalChunkHeader pointer.
    field lastChunk private type: NormalChunkHeader pointer.

    field quantumSpacedCategoryStates type: (QuantumSpacedCategoryState array: QuantumSpacedCategories + 1).

    method allocateInitializedWithZero: (size: UIntPointer) ::=> Void pointer := {
        let result := self allocate: size.
        result ifNotNil: {
            Stdn memset(result, 0, size).
        }.

        result
    }.

    method reallocate: (pointer: Void pointer) withNewSize: (newSize: UIntPointer) ::=> Void pointer := {
        pointer ifNil: {
            return: (self allocate: newSize)
        }.

        let size := self getAllocationSize: pointer.
        size >= newSize ifTrue: {
            pointer
        } ifFalse: {
            let newPointer := self allocate: newSize.
            memcpy(newPointer, pointer, size).
            self free: pointer.
            newPointer
        }
    }.

    method allocate: (size: UIntPointer) ::=> Void pointer := {
        size == 0 ifTrue: {
            return: nil
        }.

        ## Is this a large allocation?
        size >= LargeAllocationThreshold ifTrue: {
            ## Is this a huge allocation?
            size >= HugeAllocationThreshold ifTrue: {
                self allocateHuge: size.
            } ifFalse: {
                self allocateLarge: size
            }
        } ifFalse: {
            self allocateSmall: size
        }
    }.

    method getAllocationSize: (pointer: Void pointer) ::=> UIntPointer := {
        pointer ifNil: {
            return: 0
        }.

        ## Get the base address of the chunk.
        let pointerAddress := pointer reinterpretCastTo: UIntPointer.
        let chunkAddress := pointerAddress floorAlignedTo: MemoryChunkAlignment.
        let commonChunkPointer := chunkAddress reinterpretCastTo: CommonChunkHeader pointer.

        ## Is this a chunk for a huge allocation?.
        commonChunkPointer _ isHugeAllocation ifTrue: {
            let hugeChunkHeader := chunkAddress reinterpretCastTo: HugeChunkHeader pointer.
            return: hugeChunkHeader _ allocationSize.
        }.

        mutex withLock: {
            ## We are dealing with a normal chunk.
            let normalChunkHeader := chunkAddress reinterpretCastTo: NormalChunkHeader pointer.
            let chunkOffset := pointerAddress - chunkAddress.
            let buddyBlockIndex := chunkOffset / MemoryChunkBlockSize.

            ## Get the starting block of the slab.
            let slabBlockIndex := normalChunkHeader _ buddyMemoryAllocator getSlabBlockOrInvalid: buddyBlockIndex.

            slabBlockIndex ~~ ChunkBuddyMemoryAllocator InvalidBlockIndex ifTrue: {
                let slabAddress := chunkAddress + (slabBlockIndex * MemoryChunkBlockSize castTo: UIntPointer).
                let slabHeader := slabAddress reinterpretCastTo: SlabHeader pointer.

                slabHeader _ elementSize
            } ifFalse: {
                ## This is a large allocation, ask the buddy memory allocator about the allocated block count.
                (normalChunkHeader _ buddyMemoryAllocator getAllocatedBlockCountAt: buddyBlockIndex) * MemoryChunkBlockSize
            }

        }.
    }.

    method sweepAllocationsWhen: (sweepPredicateBlock: SweepPredicateBlock) ::=> Void := {
        mutex withLock: {
            self doSweepAllocationsWhen: sweepPredicateBlock
        }.
    }.

    method doSweepAllocationsWhen: (sweepPredicateBlock: SweepPredicateBlock) ::=> Void := {
        let currentChunk mutable := firstChunk.
        while: currentChunk isNotNil do: {
            let nextChunk := currentChunk _ nextChunk.
            self doSweepAllocationsWhen: sweepPredicateBlock inChunk: currentChunk.
            currentChunk := nextChunk.
        }.
    }.

    method doSweepAllocationsWhen: (sweepPredicateBlock: SweepPredicateBlock) inChunk: (chunk: NormalChunkHeader pointer)::=> Void := {
        let chunkAddress := chunk reinterpretCastTo: UIntPointer.
        ##Stdn stdout << "Iterate chunk: " << chunk; nl.
        chunk _ buddyMemoryAllocator allocatedBlocksDo: {:blockIndex :blockCount :isSlab |
            blockIndex = 0 ifFalse: {
                let blockAddress := chunkAddress + (blockIndex * MemoryChunkBlockSize castTo: UIntPointer).
                ##Stdn stdout << (blockAddress reinterpretCastTo: Void pointer) << " " << blockIndex << " " << blockCount << chunk; nl.
                isSlab ifTrue: {
                    let slabHeader := blockAddress reinterpretCastTo: SlabHeader pointer.
                    self doSweepAllocationsWhen: sweepPredicateBlock inChunk: chunk blockIndex: blockIndex inSlab: slabHeader
                } ifFalse: {
                    let allocation := blockAddress reinterpretCastTo: Void pointer.
                    sweepPredicateBlock(allocation) ifTrue: {
                        chunk _ buddyMemoryAllocator freeAtBlock: blockIndex
                    }.
                }.
            }.
        }.

        chunk _ isCompletelyFree ifTrue: {
            self removeChunk: chunk.
            NativeVirtualMemoryInterface freeAddressSpace: chunk size: MemoryChunkSize.
            ## stdout << "Free chunk " << normalChunkHeader; nl.
        }.
    }.

    method doSweepAllocationsWhen: (sweepPredicateBlock: SweepPredicateBlock) inChunk: (chunk: NormalChunkHeader pointer) blockIndex: (blockIndex: UIntPointer) inSlab: (slab: SlabHeader pointer) ::=> Void := {
        slab _ isCompletelyFree ifTrue: {return: void}.

        let hasFreedElement mutable := false.
        0 until: slab _ elementCount do: {:i :: Void |
            (slab _ isMarkedElement: i) ifTrue: {
                let elementAddress := (slab reinterpretCastTo: UInt8 pointer) + (SlabHeaderSize + slab _ elementSize*i).
                ##Stdn stdout << "Slab " << i << " elementAddress " << elementAddress << " " << slab _ elementCount << " " << slab _ elementSize; nl.
                sweepPredicateBlock(elementAddress) ifTrue: {
                    ##Stdn stdout << "Free slab element " << i; nl.
                    slab _ unmarkElement: i.
                    hasFreedElement := true.
                }.
            }.
        }.

        hasFreedElement ifFalse: {return: void.}.

        let categoryState ref := quantumSpacedCategoryStates[slab _ category].
        let isActiveSlab := categoryState isActiveSlab: slab.

        slab _ isCompletelyFree ifTrue: {
            isActiveSlab ifTrue: {
                categoryState deactivateSlab: slab.
            }.
            categoryState removeSlab: slab.
            chunk _ buddyMemoryAllocator freeAtBlock: blockIndex
        } ifFalse: {
            ## Maybe we need to make sure this slab active
            slab _ freeCount > 0 ifTrue: {
                isActiveSlab ifFalse: {
                    categoryState activateSlab: slab.
                }.
            }.
        }
    }.

    method free: (pointer: Void pointer) ::=> Void := {
        ## Ignore null pointers.
        pointer ifNil: {
            return: nil
        }.

        ## Get the base address of the chunk.
        let pointerAddress := pointer reinterpretCastTo: UIntPointer.
        let chunkAddress := pointerAddress floorAlignedTo: MemoryChunkAlignment.
        let commonChunkPointer := chunkAddress reinterpretCastTo: CommonChunkHeader pointer.

        ## Is this a chunk for a huge allocation?.
        commonChunkPointer _ isHugeAllocation ifTrue: {
            ## Just unmap the huge allocation.
            let hugeChunkHeader := chunkAddress reinterpretCastTo: HugeChunkHeader pointer.
            NativeVirtualMemoryInterface freeAddressSpace: hugeChunkHeader size: hugeChunkHeader _ allocationSize.
            return: nil.
        }.

        mutex withLock: {
            ## We are dealing with a normal chunk.
            let normalChunkHeader := chunkAddress reinterpretCastTo: NormalChunkHeader pointer.
            let chunkOffset := pointerAddress - chunkAddress.
            let buddyBlockIndex := chunkOffset / MemoryChunkBlockSize.

            ## Get the starting block of the slab.
            let slabBlockIndex := normalChunkHeader _ buddyMemoryAllocator getSlabBlockOrInvalid: buddyBlockIndex.

            ##stdout << pointer << " normalChunkHeader " << normalChunkHeader << " " << buddyBlockIndex << " " << slabBlockIndex; nl.

            slabBlockIndex ~~ ChunkBuddyMemoryAllocator InvalidBlockIndex ifTrue: {
                let slabAddress := chunkAddress + (slabBlockIndex * MemoryChunkBlockSize castTo: UIntPointer).
                let slabHeader := slabAddress reinterpretCastTo: SlabHeader pointer.
                let slabElementIndex := (pointerAddress - (slabAddress + SlabHeaderSize)) / slabHeader _ elementSize.

                ##stdout << "Slab " << slabHeader << " element size " << slabHeader _ elementSize << " index " << slabElementIndex; nl.

                ## Mark the element as free in the slab.
                slabHeader _  unmarkElement: slabElementIndex.

                ## Ensure the slab is active, or it is freed.
                self processSlabWithFreedElement: slabHeader blockIndex: slabBlockIndex inChunk: normalChunkHeader.

            } ifFalse: {
                ## This is a large allocation, we need to free the corresponding buddy.
                self freeLargeAllocationBlock: buddyBlockIndex inChunk: normalChunkHeader.
            }
        }
    }.


    #**
     * This makes sure the slab is active, or it is completely freed, after freeing an element.
     *#
    method processSlabWithFreedElement: (slabHeader: SlabHeader pointer) blockIndex: (slabBlockIndex: UIntPointer) inChunk: (normalChunkHeader: NormalChunkHeader pointer) ::=> Void := {
        let categoryState ref := quantumSpacedCategoryStates[slabHeader _ category].
        let isActiveSlab := categoryState isActiveSlab: slabHeader.

        slabHeader _ isCompletelyFree ifTrue: {
            isActiveSlab ifTrue: {
                categoryState deactivateSlab: slabHeader.
            }.
            categoryState removeSlab: slabHeader.
            self freeLargeAllocationBlock: slabBlockIndex inChunk: normalChunkHeader
        } ifFalse: {
            ## Maybe we need to make sure this slab active
            slabHeader _ freeCount > 0 ifTrue: {
                isActiveSlab ifFalse: {
                    categoryState activateSlab: slabHeader.
                }.
            }.
        }
    }.

    #**
     * This frees a large allocation through the buddy memory allocator.
     *#
    method freeLargeAllocationBlock: (buddyBlockIndex: UIntPointer) inChunk: (normalChunkHeader: NormalChunkHeader pointer) ::=> Void := {
        ##stdout << normalChunkHeader << " normalChunkHeader initialFreeBlockCount " << normalChunkHeader _ initialFreeBlockCount << " " << normalChunkHeader _ buddyMemoryAllocator currentFreeLeafBlockCount; nl.

        normalChunkHeader _ buddyMemoryAllocator freeAtBlock: buddyBlockIndex.

        ##stdout << normalChunkHeader << " normalChunkHeader initialFreeBlockCount " << normalChunkHeader _ initialFreeBlockCount << " " << normalChunkHeader _ buddyMemoryAllocator currentFreeLeafBlockCount; nl.
        normalChunkHeader _ isCompletelyFree ifTrue: {
            self removeChunk: normalChunkHeader.
            NativeVirtualMemoryInterface freeAddressSpace: normalChunkHeader size: MemoryChunkSize.
            ## stdout << "Free chunk " << normalChunkHeader; nl.
        }.
    }.

    #**
     * Small allocation
     *#
    method allocateSmall: (size: UIntPointer) ::=> Void pointer := {
        size <= 512 ifTrue: {
            self allocateQuantumSpaced: size
        } ifFalse: {
            self allocateLarge: size
        }
    }.

    #**
     * Quantum spaced allocations.
     *#
    method allocateQuantumSpaced: (size: UIntPointer) ::=> Void pointer := {
        let category := (size + 15) / 16.

        mutex withLock: {
            ## Make sure there is an active run in the category.
            let categoryState ref := quantumSpacedCategoryStates[category].
            categoryState firstActiveSlab ifNil: {
                self createSlabForQuantumSpacedCategory: category.
                categoryState firstActiveSlab ifNil: {
                    return: nil
                }
            }.

            ## Fetch the slab and some of its pointers.
            let slab := categoryState firstActiveSlab.
            let slabBytes := slab reinterpretCastTo: UInt8 pointer.
            let slabData := slabBytes[SlabHeaderSize] address.

            let freeElementIndex := slab _ findFreeElementIndex.
            assert: freeElementIndex >= 0.

            ##stdout << "Allocate from active category slab: " << categoryState firstActiveSlab << " element " << freeElementIndex; nl.
            slab _ markElement: (freeElementIndex castTo: UIntPointer).

            ## If we fill the slab, make it unactive.
            slab _ freeCount == 0 ifTrue: {
                categoryState deactivateSlab: slab
            }.

            ## Compute the pointer into the allocated slab element.
            let slabElementPointer := slabData[slab _ elementSize * freeElementIndex] address.

            ## Return the slab element pointer
            slabElementPointer
        }
    }.

    #**
     * Creates a slab
     *#
    method createSlabForQuantumSpacedCategory: (category: UIntPointer) ::=> SlabHeader pointer := {
        let categoryElementSize := category * 16.
        let allocationSize := SlabHeaderSize + categoryElementSize * 33 alignedTo: 4096. ## Go for no more than 3 % of overheader

        ## Compute an initial best element count estimate.
        let elementCount := (allocationSize - SlabHeaderSize) / categoryElementSize.

        ## Allocate the slab
        let slab := (self doAllocateLarge: allocationSize forSlab: true) reinterpretCastTo: UInt8 pointer.
        slab ifNil: {
            return: nil
        }.

        ## Clear the slab memory.
        memset(slab, 0, allocationSize).

        ## Set the slab header.
        let slabHeader := slab reinterpretCastTo: SlabHeader pointer.
        slabHeader _
            elementSize: (categoryElementSize castTo: UInt16);
            category: (category castTo: UInt8);
            setupForElements: elementCount.

        ## Put the slab in the linked list.
        let categoryState ref := quantumSpacedCategoryStates[category].
        categoryState
            addSlab: slabHeader;
            activateSlab: slabHeader.

        ##stdout << "Slab category: " << category << " allocationSize " << allocationSize << " element count " << elementCount; nl.
        slabHeader
    }.

    #**
     * Large allocation. Buddy memory allocation system.
     *#
    method allocateLarge: (size: UIntPointer) ::=> Void pointer := {
        mutex withLock: {
            self doAllocateLarge: size forSlab: false
        }
    }.

    method doAllocateLarge: (size: UIntPointer) forSlab: (isForSlab: Boolean8) ::=> Void pointer := {
        ## Find or create the chunk.
        let chunk := self findOrCreateChunkWithAvailableSize: size.
        chunk ifNil: {
            return: nil
        }.

        ##stdout << "Allocate in chunk " << chunk << " size " << size; nl.

        ## Allocate the blocks
        let blockCount := self blockCountForSize: size.
        let allocatedBlock := chunk _ buddyMemoryAllocator allocateBlocks: blockCount forSlab: isForSlab.
        assert: allocatedBlock ~~ ChunkBuddyMemoryAllocator InvalidAllocation.

        ## Get the allocation memory.
        let chunkOffset := allocatedBlock*MemoryChunkBlockSize.
        let allocationMemory := (chunk reinterpretCastTo: UInt8 pointer)[chunkOffset] address.

        ##stdout << "Allocated block " << allocatedBlock << " pointer: " << allocationMemory; nl.

        ## Return a pointer into the actual allocated memory
        allocationMemory
    }.

    #**
     * Huge allocation. This creates a dedicated mmap.
     *#
    method allocateHuge: (size: UIntPointer) ::=> Void pointer := {
        mutex withLock: {
            ## Compute the size of the allocation.
            let allocationSize := size + HugeChunkHeaderSize alignedTo: 4096.
            ##stdout << "Allocate large memory chunk of size " << allocationSize; nl.

            ## Allocate the super-chunk.
            let largeAllocation := (NativeVirtualMemoryInterface reserveAndCommitAddressSpace: allocationSize alignment: MemoryChunkAlignment) reinterpretCastTo: UInt8 pointer.
            largeAllocation ifNil: {
                return: nil
            }.

            ##stdout << "Allocated large memory chunk: " << largeAllocation; nl.

            ## Set the header.
            let header := largeAllocation reinterpretCastTo: HugeChunkHeader pointer.
            header _ commonHeader isHugeAllocation: true.
            header _ allocationSize: size.

            ## Return the allocated memory.
            largeAllocation[HugeChunkHeaderSize] address.
        }
    }.

    #**
     * Allocates a new memory chunk.
     *#
    method allocateNewChunk => NormalChunkHeader pointer := {
        let chunk := (NativeVirtualMemoryInterface reserveAndCommitAddressSpace: MemoryChunkSize alignment: MemoryChunkAlignment) reinterpretCastTo: NormalChunkHeader pointer.
        ##stdout << "Allocated memory chunk: " << chunk; nl.

        chunk ifNil: {
            return: nil
        }.

        ## Store the chunk in a linked list.
        self addChunk: chunk.

        ## Allocate the chunk header in the buddy memory allocator.
        ##stdout << "NormalChunkHeader instanceSize " << (NormalChunkHeader instanceSize castTo: UIntPointer); nl.
        chunk _ buddyMemoryAllocator
            initialize;
            allocateBlocks: (self blockCountForSize: NormalChunkHeader instanceSize) forSlab: false.
        chunk _ initialFreeBlockCount: chunk _ buddyMemoryAllocator currentFreeLeafBlockCount.

        chunk
    }.

    #**
     * Adds a chunk into the list of chunks.
     *#
    method addChunk: (chunk: NormalChunkHeader pointer) ::=> Void := {
        ## Put the chunk in the beginning of the double linked list.
        firstChunk ifNil: {
            firstChunk := lastChunk := chunk.
        } ifNotNil: {
            chunk _ nextChunk: firstChunk.
            firstChunk _ previousChunk: chunk.
            firstChunk := chunk.
        }.
    }.

    #**
     * Removes a chunk from the linked list of chunks.
     *#
    method removeChunk: (chunk: NormalChunkHeader pointer) ::=> Void := {
        chunk _ previousChunk ifNil: {
            firstChunk := chunk _ nextChunk.
        } ifNotNil: {
            chunk _ previousChunk _ nextChunk: chunk _ nextChunk
        }.

        chunk _ nextChunk ifNil: {
            lastChunk := chunk _ previousChunk.
        } ifNotNil: {
            chunk _ nextChunk _ previousChunk: chunk _ previousChunk
        }.

        chunk _
            nextChunk: nil;
            previousChunk: nil.
    }.

    #**
     * This computes the number of required blocks for a given size.
     *#
    method blockCountForSize: (size: UIntPointer) ::=> UIntPointer
        := (size + MemoryChunkBlockSize - 1) / MemoryChunkBlockSize.

    #**
     * Finds a chunk with the required available size.
     *#
    method findChunkWithAvailableSize: (requiredSize: UIntPointer) ::=> NormalChunkHeader pointer := {
        firstChunk ifNil: {
            return: nil
        }.

        let requiredBlocks := self blockCountForSize: requiredSize.
        let requiredLevel := firstChunk _ buddyMemoryAllocator findLevelForBlockCount: requiredBlocks.
        ##stdout << "findChunkWithAvailableSize level " << requiredLevel; nl.

        ## Linearly find a chunk with the requred size.
        ## TODO: Sort the chunks in an AVL tree.
        let currentChunk mutable := firstChunk.
        while: currentChunk isNotNil do: {
            (currentChunk _ buddyMemoryAllocator hasFreeBlockInLevel: requiredLevel) ifTrue: {
                return: currentChunk
            }
        } continueWith: (currentChunk := currentChunk _ nextChunk).

        nil
    }.

    #**
     * Finds a chunk with the required available size.
     *#
    method findOrCreateChunkWithAvailableSize: (requiredSize: UIntPointer) ::=> NormalChunkHeader pointer := {
        let chunk := self findChunkWithAvailableSize: requiredSize.
        chunk
            ifNotNil: {chunk}
            ifNil: {self allocateNewChunk}.
    }.
}.

}. ## End of namespace Memory
}. ## End of namespace Stdn
